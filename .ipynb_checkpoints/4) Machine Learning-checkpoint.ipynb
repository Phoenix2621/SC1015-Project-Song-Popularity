{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a328dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "music = pd.read_csv(\"machinelearning_music.csv\")\n",
    "music"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225bd9c8",
   "metadata": {},
   "source": [
    "# 4) Machine Learnning\n",
    "\n",
    "We will use 2 predictive models to discover possible patterns in our dataset and make predictions based on them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c064a752",
   "metadata": {},
   "source": [
    "#### 4a) Encode categorical data\n",
    "\n",
    "Most Machine Learning algorithms cannot work with strings; they expect to see numerical values in each feature. It is preferable to one-hot encode categorical features (those having string values), i.e., to expand number of features so that values for each class are placed in a separate column. Where the sample correspond to the given class, it gets 1 in the respective feature; all others get zeroes. Instead, categorical values in this exercise are encoded with LabelEncoder(). It assigns a number (integer) to each class. Thus, 5 distinctive classes in a categorical variable will get values between 0 and 4. It should be noted here that LabelEncoder() memorizes the classes. Therefore, an encoder is instantiated for each categorical variable. The labels (i.e., the music genre) are not encoded, which will make interpretation easier and more understandable. Tree-based algorithms accept string labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b148be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b064f04a",
   "metadata": {},
   "source": [
    "Encoding key feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273f6c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_encoder = LabelEncoder()\n",
    "music[\"key\"] = key_encoder.fit_transform(music[\"key\"])\n",
    "music.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f103b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out corresponding classes\n",
    "key_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f87f5",
   "metadata": {},
   "source": [
    "Encoding mode feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d98b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_encoder = LabelEncoder()\n",
    "music[\"mode\"] = mode_encoder.fit_transform(music[\"mode\"])\n",
    "music.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5baff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out corresponding classes\n",
    "\n",
    "mode_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae19d21",
   "metadata": {},
   "source": [
    "#### 4b) Exploration and Visualization\n",
    "\n",
    "Perform basic statistical exploration and visualization on the Train Set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e11f15",
   "metadata": {},
   "source": [
    "We will start by setting up a Multi-Variate Classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6291b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(music[\"music_genre\"])\n",
    "predictors = [\"popularity\",\"acousticness\",\"danceability\",\"duration_ms\",\"energy\",\"instrumentalness\",\"key\",\"liveness\",\"loudness\",\"mode\",\"speechiness\",\"tempo\",\"valence\"]\n",
    "X = pd.DataFrame(music[predictors]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6333fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Check the sample sizes\n",
    "print(\"Train Set :\", y_train.shape, X_train.shape)\n",
    "print(\"Test Set  :\", y_test.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed310a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics for Response\n",
    "y_train[\"music_genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics for Predictors\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b64919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the distribution of Response\n",
    "sns.catplot(y = \"music_genre\", data = y_train, kind = \"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dca303",
   "metadata": {},
   "source": [
    "## 4c) Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b698f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier model from Scikit-Learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 3)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "y_predict = dectree.fit(X_train,y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb1a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trained Decision Tree\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "f = plt.figure(figsize=(30,20))\n",
    "plot_tree(dectree, filled=True, rounded=True, fontsize = 7, \n",
    "          feature_names= X_train.columns, \n",
    "          class_names= [\"Classical\",\"Jazz\",\"Country\",\"Rock\",\"Hip-Hop\",\"Rap\",\"Anime\",\"Alternative\",\"Blues\",\"Electronic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ada5ab",
   "metadata": {},
   "source": [
    "## 4d) Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd9632c",
   "metadata": {},
   "source": [
    "#### We start by Finding Optimal Depth via K-fold Cross-Validation\n",
    "We use a range of tree depths to evaluate and to plot the estimated performance +/- 2 standard deviations for each depth using K-fold cross validation. We provide a Python code that can be used in any situation, where you want to tune your decision tree given a predictor tensor X and labels Y. The code includes the training set performance in the plot, while scaling the y-axis to focus on the cross-validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd156301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# function for fitting trees of various depths on the training data using cross-validation\n",
    "def run_cross_validation_on_trees(X, y, tree_depths, cv=5, scoring='accuracy'):\n",
    "    cv_scores_list = []\n",
    "    cv_scores_std = []\n",
    "    cv_scores_mean = []\n",
    "    accuracy_scores = []\n",
    "    for depth in tree_depths:\n",
    "        tree_model = DecisionTreeClassifier(max_depth=depth)\n",
    "        cv_scores = cross_val_score(tree_model, X, y, cv=cv, scoring=scoring)\n",
    "        cv_scores_list.append(cv_scores)\n",
    "        cv_scores_mean.append(cv_scores.mean())\n",
    "        cv_scores_std.append(cv_scores.std())\n",
    "        accuracy_scores.append(tree_model.fit(X, y).score(X, y))\n",
    "    cv_scores_mean = np.array(cv_scores_mean)\n",
    "    cv_scores_std = np.array(cv_scores_std)\n",
    "    accuracy_scores = np.array(accuracy_scores)\n",
    "    return cv_scores_mean, cv_scores_std, accuracy_scores\n",
    "  \n",
    "# function for plotting cross-validation results\n",
    "def plot_cross_validation_on_trees(depths, cv_scores_mean, cv_scores_std, accuracy_scores, title):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(15,5))\n",
    "    ax.plot(depths, cv_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)\n",
    "    ax.fill_between(depths, cv_scores_mean-2*cv_scores_std, cv_scores_mean+2*cv_scores_std, alpha=0.2)\n",
    "    ylim = plt.ylim()\n",
    "    ax.plot(depths, accuracy_scores, '-*', label='train accuracy', alpha=0.9)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('Tree depth', fontsize=14)\n",
    "    ax.set_ylabel('Accuracy', fontsize=14)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_xticks(depths)\n",
    "    ax.legend()\n",
    "\n",
    "# fitting trees of depth 1 to 24\n",
    "sm_tree_depths = range(1,25)\n",
    "sm_cv_scores_mean, sm_cv_scores_std, sm_accuracy_scores = run_cross_validation_on_trees(X_train, y_train, sm_tree_depths)\n",
    "\n",
    "# plotting accuracy\n",
    "plot_cross_validation_on_trees(sm_tree_depths, sm_cv_scores_mean, sm_cv_scores_std, sm_accuracy_scores, \n",
    "                               'Accuracy per decision tree depth on training data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d56c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing out the optimum depth\n",
    "\n",
    "idx_max = sm_cv_scores_mean.argmax()\n",
    "sm_best_tree_depth = sm_tree_depths[idx_max]\n",
    "sm_best_tree_cv_score = sm_cv_scores_mean[idx_max]\n",
    "sm_best_tree_cv_score_std = sm_cv_scores_std[idx_max]\n",
    "print('The depth-{} tree achieves the best mean cross-validation accuracy {} +/- {}% on training dataset'.format(\n",
    "      sm_best_tree_depth, round(sm_best_tree_cv_score*100,5), round(sm_best_tree_cv_score_std*100, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9669f862",
   "metadata": {},
   "source": [
    "The method selects tree depth 10 because it achieves the best average accuracy on training data using cross-validation folds with size 5. The lower bound of the confidence interval of the accuracy is high enough to make this value significant. When more nodes are added to the tree, it is clear that the cross-validation accuracy changes towards zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df7a1c",
   "metadata": {},
   "source": [
    "#### Now we print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62276eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(music['music_genre'])\n",
    "X = pd.DataFrame(music[predictors])\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25) \n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 10)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(25, 10))\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 10}, ax = axes[0])\n",
    "sns.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 10}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c10737",
   "metadata": {},
   "source": [
    "In the above confusion matrix, 0-9 are the indexes for [\"Classical\",\"Jazz\",\"Country\",\"Rock\",\"Hip-Hop\",\"Rap\",\"Anime\",\"Alternative\",\"Blues\",\"Electronic\"] respectively\n",
    "\n",
    "The \"Goodness of Fit\" refers to the performance of the model, which has been evaluated using the accuracy metric. The accuracy metric measures the proportion of correctly classified instances out of all instances.\n",
    "\n",
    "In this case, the model was trained on a training dataset and tested on a separate testing dataset. The classification accuracy for the training dataset was found to be 0.601, which means that the model correctly classified 60.1% of the instances in the training dataset. The classification accuracy for the testing dataset was found to be 0.512, which means that the model correctly classified 51.2% of the instances in the testing dataset.\n",
    "\n",
    "This shows that the decision tree may be an optimal model for predicting song genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a594f124",
   "metadata": {},
   "source": [
    "# 4.2a) Basic exploration\n",
    "\n",
    "Second modeling: Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a38bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "rf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a97024",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "sns.set(font_scale=.75)\n",
    "cnf1 = confusion_matrix(y_pred,y_test)\n",
    "sns.heatmap(cnf1,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd91d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ceb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
